import os
import streamlit as st
import logging
from typing import List, Dict, Any
import time

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from document_fetcher import DocumentFetcher
from document_processor import DocumentProcessor
from text_chunker import TextChunker
from embedding_generator import EmbeddingGenerator
from vector_store import VectorStore
from gpt_responder import GPTResponder

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì™¸ë¶€ ì¸ì¦ ë¬¸ì„œ ê¸°ë°˜ RAG í•œêµ­ì–´ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
    st.session_state.messages = []
    st.session_state.vector_store = None
    st.session_state.embedding_generator = None
    st.session_state.responder = None
    st.session_state.documents_info = None

# ì‚¬ì´ë“œë°”ì— ì…ë ¥ í¼ ì¶”ê°€
with st.sidebar:
    st.title("ğŸ¤– RAG ì±—ë´‡ ì„¤ì •")
    
    with st.expander("API ì„¤ì •", expanded=not st.session_state.initialized):
        openai_api_key = st.text_input("OpenAI API í‚¤", type="password", 
                                      value=os.getenv("OPENAI_API_KEY", ""))
        gpt_model = st.selectbox("GPT ëª¨ë¸", 
                                options=["gpt-3.5-turbo", "gpt-4"], 
                                index=0)
    
    with st.expander("ë¬¸ì„œ API ì„¤ì •", expanded=not st.session_state.initialized):
        api_url = st.text_input("API ì—”ë“œí¬ì¸íŠ¸ URL", 
                               value=os.getenv("API_URL", ""))
        
        auth_type = st.radio("ì¸ì¦ ë°©ì‹", 
                            options=["Bearer í† í°", "API í‚¤", "ì—†ìŒ"], 
                            index=2)
        
        if auth_type == "Bearer í† í°":
            bearer_token = st.text_input("Bearer í† í°", type="password", 
                                        value=os.getenv("BEARER_TOKEN", ""))
        elif auth_type == "API í‚¤":
            api_key = st.text_input("API í‚¤", type="password", 
                                   value=os.getenv("API_KEY", ""))
    
    with st.expander("ì²­í‚¹ ì„¤ì •"):
        chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=100, max_value=2000, value=500, step=100)
        chunk_overlap = st.slider("ì²­í¬ ì¤‘ë³µ", min_value=0, max_value=200, value=50, step=10)
    
    # ì´ˆê¸°í™” ë²„íŠ¼
    init_button = st.button("ì‹œìŠ¤í…œ ì´ˆê¸°í™”")

# ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if init_button or not st.session_state.initialized:
    with st.spinner("ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            if openai_api_key:
                os.environ["OPENAI_API_KEY"] = openai_api_key
            if api_url:
                os.environ["API_URL"] = api_url
            if auth_type == "Bearer í† í°" and bearer_token:
                os.environ["BEARER_TOKEN"] = bearer_token
            elif auth_type == "API í‚¤" and api_key:
                os.environ["API_KEY"] = api_key
            
            # ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            fetcher = DocumentFetcher()
            documents = fetcher.fetch_documents()
            
            # ë¬¸ì„œ ì²˜ë¦¬
            processor = DocumentProcessor()
            processed_docs = processor.process_documents(documents)
            
            # ì²­í¬ ìƒì„±
            chunker = TextChunker(chunk_size=chunk_size, 
                                 chunk_overlap=chunk_overlap)
            chunks = chunker.create_chunks(processed_docs)
            
            # ì„ë² ë”© ìƒì„±
            embedding_generator = EmbeddingGenerator()
            embedded_chunks = embedding_generator.generate_embeddings(chunks)
            
            # ë²¡í„° ì¸ë±ìŠ¤ì— ì¶”ê°€
            vector_store = VectorStore(embedding_generator.embedding_dim)
            vector_store.add_embeddings(embedded_chunks)
            
            # GPT ì‘ë‹µê¸° ì´ˆê¸°í™”
            responder = GPTResponder(model_name=gpt_model)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.embedding_generator = embedding_generator
            st.session_state.vector_store = vector_store
            st.session_state.responder = responder
            st.session_state.initialized = True
            
            # ë¬¸ì„œ ì •ë³´ ì €ì¥
            st.session_state.documents_info = {
                "total_docs": len(documents),
                "doc_names": [name for name, _ in documents],
                "total_chunks": len(chunks)
            }
            
            st.success(f"{len(documents)}ê°œ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  {len(chunks)}ê°œ ì²­í¬ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state.initialized = False
            logger.error(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")

# ë©”ì¸ ì½˜í…ì¸  ì˜ì—­
st.title("ğŸ“š ì™¸ë¶€ ì¸ì¦ ë¬¸ì„œ ê¸°ë°˜ RAG í•œêµ­ì–´ ì±—ë´‡")

# ë¬¸ì„œ ì •ë³´ í‘œì‹œ
if st.session_state.documents_info:
    info = st.session_state.documents_info
    st.markdown(f"""
    **ì²˜ë¦¬ëœ ë¬¸ì„œ**: {info['total_docs']}ê°œ | **ì´ ì²­í¬ ìˆ˜**: {info['total_chunks']}ê°œ
    
    **ë¬¸ì„œ ëª©ë¡**: {', '.join(info['doc_names'][:5])}{'...' if len(info['doc_names']) > 5 else ''}
    """)

# ë©”ì‹œì§€ ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if st.session_state.initialized:
    user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    if user_query:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_query})
        
        with st.chat_message("user"):
            st.write(user_query)
        
        # ë‹µë³€ ìƒì„± ê³¼ì •
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                # ì„ë² ë”© ìƒì„±
                try:
                    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                    embedding_generator = st.session_state.embedding_generator
                    query_embedding = embedding_generator.get_embedding(user_query)
                    
                    # ë²¡í„° ê²€ìƒ‰
                    vector_store = st.session_state.vector_store
                    results = vector_store.search(query_embedding, top_k=3)
                    
                    if results:
                        # ë§¥ë½ ê¸°ë°˜ ë‹µë³€ ìƒì„±
                        message_placeholder = st.empty()
                        
                        # ë‚´ìš© í‘œì‹œ (ìŠ¤íŠ¸ë¦¬ë° ì—†ì´)
                        responder = st.session_state.responder
                        response = responder.generate_response(user_query, results)
                        message_placeholder.markdown(response)
                        
                        # ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    else:
                        error_msg = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                
                except Exception as e:
                    error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    logger.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
else:
    st.info("ğŸ‘ˆ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ë ¤ë©´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í•„ìš”í•œ ì„¤ì •ì„ ì…ë ¥í•˜ê³  'ì‹œìŠ¤í…œ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("ğŸ” **ì™¸ë¶€ ì¸ì¦ ë¬¸ì„œ ê¸°ë°˜ RAG í•œêµ­ì–´ ì±—ë´‡** - ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ") 